================================================================================
           HDFC Lead Prediction - ML Pipeline Execution Steps
================================================================================

This document explains how to run the Training and Inference pipelines.


--------------------------------------------------------------------------------
                             PREREQUISITES
--------------------------------------------------------------------------------

1. Make sure you have Python 3.8+ installed

2. Navigate to the project directory:
   cd /path/to/ML_End_To_End

3. Create a virtual environment (if not already created):
   python -m venv .venv

4. Activate the virtual environment:
   - On Mac/Linux:   source .venv/bin/activate
   - On Windows:     .venv\Scripts\activate

5. Install required packages:
   pip install -r requirements.txt


================================================================================
                            TRAINING PIPELINE
================================================================================

STEP 1: Place your data file
----------------------------
- Ensure your CSV data file is in the project root directory
- Default expected file: HDFC_TN_Leads_120k.csv
- To use a different file, update src/config/config.yaml:
  data:
    csv_filepath: "your_file_name.csv"


STEP 2: Run the training script
-------------------------------
Command:
    python main.py

What it does:
    1. Loads data from CSV file
    2. Cleans data (removes duplicates, drops unwanted columns)
    3. Extracts features from date columns
    4. Splits data into training (80%) and test (20%) sets
    5. Preprocesses data (imputes missing values, scales numerical, encodes categorical)
    6. Trains a Random Forest model with optimized parameters
    7. Evaluates model and prints metrics
    8. Logs model and metrics to MLflow
    9. Saves model to models/best_model.pkl


STEP 3: View results
--------------------
After training completes, you will see:
    - Accuracy, Precision, Recall, F1 Score
    - Classification Report
    - Model saved location


STEP 4 (Optional): View MLflow Dashboard
----------------------------------------
Command:
    mlflow ui

Then open your browser and go to:
    http://localhost:5000


================================================================================
                           INFERENCE PIPELINE
================================================================================

STEP 1: Ensure model is trained
-------------------------------
- The file models/best_model.pkl must exist
- If not, run the training pipeline first (python main.py)


STEP 2: Prepare inference data
------------------------------
- By default, inference uses the same data file as training
- To use different data, update the csv_filepath in config.yaml
- Or modify inference.py to accept a different file path


STEP 3: Run the inference script
--------------------------------
Command:
    python inference.py

What it does:
    1. Loads the trained model from models/best_model.pkl
    2. Loads and preprocesses the data
    3. Makes predictions for all records
    4. Saves results to predictions.csv


STEP 4: View predictions
------------------------
Open predictions.csv to see:
    - prediction: 0 or 1 (will convert or not)
    - probability: likelihood of conversion (0 to 1)


================================================================================
                            CONFIGURATION
================================================================================

All settings are in: src/config/config.yaml

Key settings you can modify:

1. Data Settings:
   - csv_filepath: Path to your data file
   - target_column: Name of the target column
   - drop_columns: Columns to remove from data
   - date_columns: Date columns to extract features from

2. Model Parameters:
   - n_estimators: Number of trees (default: 100)
   - max_depth: Maximum tree depth (default: 10)
   - min_samples_split: Min samples to split node (default: 2)
   - min_samples_leaf: Min samples in leaf (default: 1)

3. Output Paths:
   - model_path: Where to save the trained model


================================================================================
                              FASTAPI REST API
================================================================================

The inference pipeline is also available as a REST API using FastAPI.

STEP 1: Ensure model is trained
-------------------------------
- The file models/best_model.pkl must exist
- If not, run the training pipeline first (python main.py)


STEP 2: Install API dependencies
--------------------------------
Command:
    pip install fastapi uvicorn[standard] pydantic

(Already included in requirements.txt)


STEP 3: Start the API server
----------------------------
Command:
    uvicorn api:app --reload --port 8000

The API will be available at:
    http://localhost:8000


STEP 4: Access API Documentation
--------------------------------
FastAPI provides interactive API documentation:
    - Swagger UI: http://localhost:8000/docs
    - ReDoc:      http://localhost:8000/redoc


STEP 5: API Endpoints
---------------------
| Method | Endpoint        | Description                   |
|--------|-----------------|-------------------------------|
| GET    | /               | API information               |
| GET    | /health         | Health check & model status   |
| POST   | /predict        | Single lead prediction        |
| POST   | /predict/batch  | Batch predictions             |


STEP 6: Example API Calls
-------------------------
Single prediction (using curl):

    curl -X POST "http://localhost:8000/predict" \
         -H "Content-Type: application/json" \
         -d '{
               "gender": "Male",
               "age": 35,
               "marital_status": "Married",
               "annual_income": 750000,
               "city": "Chennai",
               "cibil_score": 750,
               "product_category": "Loans",
               "lead_source": "Website"
             }'


================================================================================
                          STREAMLIT DASHBOARD (app.py)
================================================================================

A beautiful web dashboard for batch predictions with filtering and downloads.

STEP 1: Ensure API is running
-----------------------------
The Streamlit app uses the FastAPI backend, so start the API first:
    uvicorn api:app --reload --port 8000


STEP 2: Start the Streamlit app
-------------------------------
Command:
    streamlit run app.py

The dashboard will open at:
    http://localhost:8501


STEP 3: Using the Dashboard
---------------------------
1. Upload your CSV file with lead data
2. Click "Run Predictions" button
3. View results with conversion status and reasoning
4. Filter by product, status, or confidence
5. Download results as CSV


STEP 4: Dashboard Features
--------------------------
- üìä Summary metrics (total leads, conversions, rates)
- üîç Filter by product category
- üìã View reasoning for each prediction
- üì• Download full or summary CSV
- üì¶ Product-wise breakdown and downloads


================================================================================
                              QUICK REFERENCE
================================================================================

| Task                    | Command                               |
|-------------------------|---------------------------------------|
| Train model             | python main.py                        |
| Make predictions (CLI)  | python inference.py                   |
| Start API server        | uvicorn api:app --reload --port 8000  |
| Start Dashboard         | streamlit run app.py                  |
| View API docs           | http://localhost:8000/docs            |
| View Dashboard          | http://localhost:8501                 |
| View MLflow dashboard   | mlflow ui                             |


================================================================================
                              TROUBLESHOOTING
================================================================================

1. "Module not found" error:
   - Make sure virtual environment is activated
   - Run: pip install -r requirements.txt

2. "File not found" error:
   - Check that data file exists in project root
   - Verify csv_filepath in config.yaml is correct

3. "Model not found" error (during inference or API):
   - Run training first: python main.py
   - Check models/best_model.pkl exists

4. "API Not Connected" in Streamlit:
   - Ensure FastAPI is running on port 8000
   - Run: uvicorn api:app --reload --port 8000


================================================================================
                                 END
================================================================================
